<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Daniel Kaplan">
<meta name="dcterms.date" content="2023-05-02">

<title>Math300 Blog - A Bayes interpretation of Hypothesis testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Math300 Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://dtkaplan.github.io/Math-300Z/">
 <span class="menu-text">Spring 2023 class schedule</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A Bayes interpretation of Hypothesis testing</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">likelihood</div>
                <div class="quarto-category">prior</div>
                <div class="quarto-category">posterior</div>
                <div class="quarto-category">likelihood ratio</div>
                <div class="quarto-category">odds</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Daniel Kaplan </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 2, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<p>The Bayesian paradigm provides a complete framework for competing two hypotheses against one another. We introduced that framework in the context of screening tests where the hypotheses—diseased vs healthy—are concrete, the likelihoods—p(<span class="math inline">\(\mathbb P\)</span>) | diseased) and p(<span class="math inline">\(\mathbb P\)</span> | healthy)—can be found by cross tabulation of test results and disease state.</p>
<p>This essay contrasts the Bayesian framework with Fisher’s <em>significance testing</em> and Neyman-Pearson <em>hypothesis testing</em>. The point is to show what each of these testing frameworks leaves out. To simplify the comparison, we’ll use Null and Alternative as the names for the two Bayesian hypotheses, even though Bayes allows a more general choice (or even multiple hypotheses).</p>
<p>Here is a graphic showing the three inputs to the Bayesian calculation of the posterior probability p(Alternative | obs ): i. the prior p(Alternative) and the two likelihoods ii. p(obs | Alternative) and iii. p(obs | Null).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hypothesis_compete_graph</span>(<span class="at">prior=</span>.<span class="dv">15</span>, <span class="at">like1=</span><span class="fl">0.8</span>, <span class="at">like2=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-bayes-paradigm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-bayes-paradigm-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Three inputs for the Bayesian calculation: two likelihoods and a prior. Since there are only two hypotheses, the prior on the Null is merely one minus the prior on the Alternative. The areas in the graph are calculated from these inputs: multiplying the priors by the likelihoods. The areas are used in the calculation of the output of the Bayesian test.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<section id="comparing-the-three-frameworks" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="comparing-the-three-frameworks">Comparing the three frameworks</h2>
<p>The three frameworks—Bayes, Significance, and Neymann-Pearson—all produce a outcome <strong>after</strong> data have been collected. In Bayes, this structure is more evident from the name “posterior” for the outcome, but it’s equally true in the other two frameworks.</p>
<section id="test-set-up" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="test-set-up">Test set-up</h3>
<p>The Bayes and Neymann-Pearson frameworks involve two stages; one can occur before the data observations are made, the other only after the observations.</p>
<p>In <strong>Neymann-Pearson</strong>, the set-up amounts to the study design:</p>
<ol type="i">
<li>specification of an Alternative hypothesis. (The Null is typically obvious, e.g.&nbsp;a model coefficient would be found to be zero with infinite data.)</li>
<li>what data is to be collected and what test statistic to use to summarize the data,</li>
<li>determining the sample size.</li>
</ol>
<p>These three items go into a calculation of the “<strong>power</strong>” of the test. The power is the conditional probability that the outcome of the test will be to reject the Null. The “given” part of the conditional probability is the Alternative hypothesis. Calculation of the power is done by simulation (or the algebraic equivalent); power does not depend on the eventual observation.</p>
<p>Study design is an iterative process which aims to find a feasible study design that maximizes the power. A study design which achieves a power of 80% is generally considered adequate.</p>
<p>In <strong>Bayes</strong> the set-up involves:</p>
<ol type="i">
<li>Selection of a prior, p(Alternative). This might be subjective or based on existing knowledge (before the data are available). </li>
<li>Calculation of two likelihood <em>functions</em>, one under the Null and the other under the Alternative. Each of these functions will, eventually, be given the results from the data as input and produce a numerical likelihood as the output.  These functions are often produced by applying a relevant probability model.</li>
</ol>
<div class="no-row-height column-margin column-container"><span class="">In the case of screening tests, the prior amounts to the prevalence of the disease in the relevant population.</span><span class="">With screening tests, this calculation is simple because there are only two possible results from the data: <span class="math inline">\(\mathbb P\)</span> or <span class="math inline">\(\mathbb N\)</span>. The research project which developed the test determines the sensitivity and specificity, p(<span class="math inline">\(\mathbb P\)</span> | Alternative) and p(<span class="math inline">\(\mathbb N\)</span> | Null). The likelihood functions consist of these two likelihoods and their complements.</span></div><p><strong>Significance</strong> testing has <strong>no set-up phase</strong>. This is one of the most attractive features of the framework.</p>
</section>
<section id="allowed-inputs-to-determine-the-test-output" class="level3">
<h3 class="anchored" data-anchor-id="allowed-inputs-to-determine-the-test-output">Allowed inputs to determine the test output</h3>
<p>Neither <strong>Significance</strong> nor <strong>Neymann-Pearson</strong> need a prior to be specified for either hypothesis. <strong>Bayes</strong> requires a prior for both. [In the Bayesian framework, the prior on the Null is simply 1 minus the prior on the Alternative. So only one of the priors needs to be specified.]</p>
<p>::: {#fig-fisher-neymann diagrams .cell .column-page-right layout-ncol=“2”} ::: {.cell-output-display} <img src="index_files/figure-html/fig-fisher-neymann diagrams-1.png" class="img-fluid" alt="Significance framework">{#fig-fisher-neymann diagrams-1 width=672} :::</p>
<div class="cell-output-display">
<p><img src="index_files/figure-html/fig-fisher-neymann diagrams-2.png" class="img-fluid" alt="Neymann-Pearson framework">{#fig-fisher-neymann diagrams-2 width=672}</p>
</div>
<p>Modification of the Bayes diagram showing the information used to determine the outputs from the Significance framework and Neymann-Pearson framework. :::</p>
</section>
<section id="calculation-of-test-output" class="level3">
<h3 class="anchored" data-anchor-id="calculation-of-test-output">Calculation of test output</h3>
<p><strong>Significance</strong> framework: The likelihood of the observation under the Null hypothesis is calculated and called the “p-value.” If p is small (usually p &lt; 0.05) then the output is “reject the Null.” Otherwise the output is “fail to reject the Null.”</p>
<p><strong>Neymann-Pearson</strong> framework: Same as for the Significance framework. (Note that the power isn’t used for the calculation of the test output. It’s only involved in the study design.)</p>
<p><strong>Bayes</strong> framework: The test output is a posterior probability, not a phrase like “reject the Null.” Calculation of the posterior can be stated in terms of the two areas shown in the graph:</p>
<p>p(Alternative | Obs) = green/(green + blue)</p>
<p>For the example in <a href="#fig-bayes-paradigm">Figure&nbsp;1</a>, this amounts to 0.12/(0.12+0.17) = 41%. That’s about three times larger than the prior on the Alternative.</p>
</section>
</section>
<section id="alignment-of-the-tests" class="level2">
<h2 class="anchored" data-anchor-id="alignment-of-the-tests">Alignment of the tests</h2>
<p>The output of the <strong>Significance</strong> and <strong>Neymann-Pearson</strong> tests is always the same, at least if the study design calculated under Neymann-Pearson happened to be the same as for Significance testing.</p>
<p>The output from the <strong>Bayes</strong> framework can be compatible or not, depending as it does on the choice of prior and the likelihood under the Alternative hypothesis.</p>
<p>Purely for the sake of comparison, let’s look at the Significance and Neymann-Pearson calculations as if there were a meaningful prior in those frameworks.</p>
</section>
<section id="the-bayesian-paradigm" class="level2">
<h2 class="anchored" data-anchor-id="the-bayesian-paradigm">The Bayesian paradigm</h2>
<p>The Bayesian paradigm is not limited to considering only two hypotheses; that’s just one setting for it. Let’s adopt this setting, accepting the names “Null” and “Alternative” for the two competing hypotheses. The Bayesian calculation of the posterior requires statement of a prior for each of the hypotheses. (The prior for one hypothesis will be one minus the prior of the other.)</p>
<p>There is a nice version of the Bayes calculation in terms of the likelihood ratio and prior and posterior <em>odds</em>.</p>
<p><span class="math display">\[\underbrace{odds(H_a | \text{obs})}_{\Large\text{posterior for } H_a} = \underbrace{\left[\frac{{\cal L}_a(\text{obs})}{{\cal L}_0(\text{obs})} \right]}_{\Large\text{Likelihood ratio}}\ \times\ \underbrace{odds(H_a)}_{\Large\text{prior for } H_a}\]</span></p>
<p>If we stipulate that the same prior odds applies to all three frameworks, the critical quantity in shaping the posterior odds is the “likelihood ratio.” A large likelihood ratio pushes the posterior odds on the Alternative higher, which is analogous to “reject the Null.”</p>
<p>The argument being made here is that a small p-value corresponds to a large likelihood ratio.</p>
<p>In <strong>Significance</strong> testing, there is no such thing as <span class="math inline">\({\cal L}_a(obs)\)</span>: the only quantity that comes into the test is <span class="math inline">\({\cal L}_0(obs)\)</span>. The same is true in <strong>Neymann-Pearson</strong>, but the “power” has a similar spirit to <span class="math inline">\({\cal L}_a(obs)\)</span>. Let’s use 80% (the convention for adequate power) is a placeholder for <span class="math inline">\({\cal L}_a(obs)\)</span>, but the precise value is not critical to the argument, just that there is some non-zero placeholder.</p>
<p>In <strong>Significance</strong> and <strong>Neymann-Pearson</strong> <span class="math inline">\({\cal L}_0(obs)\)</span> is called the p-value. A low p-value (conventionally, p &lt; 0.05) argues against the Null. Using the placeholder for <span class="math inline">\({\cal L}_a(obs)\)</span>, a low p-value leads to a high likelihood ratio, which argues for the Alternative.</p>
<p>Since the <strong>Significance</strong> framework has nothing even analogous to <span class="math inline">\({\cal L}_a(obs)\)</span>, the choice of the threshold level (e.g.&nbsp;p &lt; 0.05) is never informed by the setting for data collection.</p>
<p>In <strong>Neymann-Pearson</strong>, the power is analogous to <span class="math inline">\({\cal L}_a(obs)\)</span>. Using a power of 80%, then p &lt; 0.05 corresponds to a likelihood ratio of 16 or more. Likelihoods in this range are often described as providing “strong evidence” in favor of the Alternative.</p>
</section>
<section id="strength-of-evidence" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="strength-of-evidence">“Strength of evidence”</h2>
<p>It is common to describe the p-value as measuring the “strength of evidence” against the Null hypothesis. For instance, p=0.10 is described as “weak” evidence, while <span class="math inline">\(p=0.001\)</span> constitutes “strong” evidence.</p>
<p>In the Bayes framework, “strength of evidence” can be given a reasonable mathematical definition: the likelihood ratio. The “strength of evidence” is the balance (or lack thereof) between <span class="math inline">\({\cal L}_0(obs)\)</span> and <span class="math inline">\({\cal L}_a(obs)\)</span>.</p>
<p>In the Significance and Neymann-Pearson frameworks, there is no such thing as <span class="math inline">\({\cal L}_a(obs)\)</span>. Lacking that, <span class="math inline">\({\cal L}_0(obs)\)</span> has nothing to be balanced against. In other words, without a <span class="math inline">\({\cal L}_a(obs)\)</span>, there is no way to define what constitutes a very “small” <span class="math inline">\({\cal L}_0(obs)\)</span>. “Small” can only be defined relevant to the general convention, p &lt; 0.05, which is arbitrary. The only way in which a p-value like 0.001 is “small” is that it is below 0.05. No further claim is justified.</p>
<p>Fairness to Fisher and the Significance framework requires that his actual description of the method (e.g.&nbsp;p &lt; 0.05) be considered, as opposed to the interpretation that is been layered on top of it by later research workers.</p>
<div class="page-columns page-full"><p>In his 1926 paper introducing Significance testing, Fisher wrote about the 0.05 (“one in twenty”) threshold. Note that he uses the phrase “high enough odds” where today we would say “low enough p-value.”</p><div class="no-row-height column-margin column-container"><span class="">R.A. Fisher (1926) “The arrangement of field experiments” <em>Journal of the Ministry of Agriculture of Great Britain</em> <strong>33</strong>:505-513, <a href="https://hdl.handle.net/2440/15191">link</a></span></div></div>
<blockquote class="blockquote">
<p>“<em>If one in twenty does not seem high enough odds, we may if we prefer it, draw the line at one in fifty (the 2 per cent. point), or one in a hundred (the 1 per cent. point). Personally, the writer prefers to set a low standard of significance at the 5 per cent. point, and ignore entirely all results which fail to reach this level.</em>”</p>
</blockquote>
<p>Up to this point in his narrative, Fisher’s description does not deviate from contemporary practice with <span class="math inline">\(p &lt; 0.05\)</span>, although “ignore entirely” doesn’t align with those today who interpret <span class="math inline">\(p &gt; 0.05\)</span> as supporting the Null.</p>
<p>But in the next sentences, Fisher describes what it takes for “a scientific fact [to] be regarded as experimentally established,” which I take to be much the same thing as “strength of evidence.”</p>
<blockquote class="blockquote">
<p>“<em>A scientific fact should be regarded as experimentally established only if a properly designed experiment </em>rarely fails* to give this level of significance. The very high odds sometimes claimed for experimental results should usually be discounted, for inaccurate methods of estimating error have far more influence than the particular standard of significance chosen.*”</p>
</blockquote>
<p>Neymann-Pearson’s “alternative hypothesis” and “power” are a mathematical statement of what constitutes a “properly designed experiment” and “rarely fails.”</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>